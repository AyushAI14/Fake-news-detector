{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6441eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ddd159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ayush/Documents/AI/Projects/Fake-news-detector\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a1f2002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class ModelEvalutionConfig:\n",
    "    root_dir: Path\n",
    "    model_path :  Path\n",
    "    tokenizer_path: Path\n",
    "    prediction_results : Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81580634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import * \n",
    "from src.utils.common import read_yaml_file,create_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a10f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,config=CONFIG_FILE_PATH,\n",
    "                 param=PARAM_FILE_PATH):\n",
    "        self.config=read_yaml_file(config)\n",
    "        self.param=read_yaml_file(param)\n",
    "        create_dir([self.config.root_Artifact])\n",
    "\n",
    "    def getModelEvalution(self)->ModelEvalutionConfig:\n",
    "        config=self.config.model_evalution\n",
    "        create_dir([config.root_dir])\n",
    "        model_evalution_config = ModelEvalutionConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            model_path=Path(config.model_path),\n",
    "            tokenizer_path = Path(config.tokenizer_path),\n",
    "            prediction_results=Path(config.prediction_results)\n",
    "        )\n",
    "        return model_evalution_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a3939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/Documents/AI/Projects/Fake-news-detector/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvalution:\n",
    "    def __init__(self,config=ModelEvalutionConfig):\n",
    "        self.config=config\n",
    "        self.model_path = self.config.model_path\n",
    "        self.tokenizer_path=self.config.tokenizer_path\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_path)\n",
    "        # self.model = AutoModelForSequenceClassification.from_pretrained(self.model_path)\n",
    "          # ‚¨áÔ∏è FIXED: add local_files_only=True\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_path, local_files_only=True)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_path, local_files_only=True)\n",
    "        self.model.eval()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        if not os.path.exists(self.config.prediction_results):\n",
    "            with open(self.config.prediction_results, mode='w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"text\", \"label\", \"confidence\"])\n",
    "    def predict(self,text):\n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(self.device)\n",
    "\n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            probs = F.softmax(outputs.logits, dim=-1)\n",
    "            prediction = torch.argmax(probs, dim=-1).item()\n",
    "            confidence = probs[0][prediction].item()\n",
    "\n",
    "        # Output\n",
    "        label = \"Real News\" if prediction == 1 else \"Fake News\"\n",
    "        print(f\"üì∞ Text: {text}\")\n",
    "        print(f\"üì¢ Prediction: {label} ({probs[0][prediction].item():.4f} confidence)\")\n",
    "        with open(self.config.prediction_results, mode='a', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([text, label, confidence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639e1f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-12 08:16:27,252 : INFO : common : Created directory at: artifact]\n",
      "[2025-06-12 08:16:27,257 : INFO : common : Created directory at: artifact/model_evalution]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 08:16:32.097285: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-12 08:16:32.119370: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-12 08:16:32.289786: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-12 08:16:32.450123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749696392.603853   32093 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749696392.651098   32093 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749696392.971684   32093 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749696392.971987   32093 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749696392.972007   32093 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749696392.972017   32093 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-12 08:16:33.017182: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∞ Text: India successfully lands Chandrayaan-3 near the Moon's south pole\n",
      "üì¢ Prediction: Real News (1.0000 confidence)\n"
     ]
    }
   ],
   "source": [
    "config=ConfigurationManager()\n",
    "getmodelevalConfig = config.getModelEvalution()\n",
    "modelEval = ModelEvalution(config=getmodelevalConfig)\n",
    "modelEval.predict(\"India successfully lands Chandrayaan-3 near the Moon's south pole\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
